{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.2.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl (13.9 MB)\n",
      "Requirement already satisfied: spacy<3.3.0,>=3.2.0 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from en-core-web-sm==3.2.0) (3.2.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.8)\n",
      "Requirement already satisfied: setuptools in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (58.0.4)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.21.2)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.6.1)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.7.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.9.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.6)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.13)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.26.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.6)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.3.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.11.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (21.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.62.3)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.6)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.10.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.2)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.26.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.1)\n",
      "[!] As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the full\n",
      "pipeline package name 'en_core_web_sm' instead.\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "Collecting en-core-web-sm==3.2.0\n",
      "  Using cached https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl (13.9 MB)\n",
      "Requirement already satisfied: spacy<3.3.0,>=3.2.0 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from en-core-web-sm==3.2.0) (3.2.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (58.0.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.26.0)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.13)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.62.3)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.6.1)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.7.5)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.21.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.9.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (21.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.3.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.11.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.6)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.6)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.10.0.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2021.10.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\monster\\anaconda3\\envs\\tf-gpu\\lib\\site-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.1)\n",
      "[+] Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MRP-fAQedMTd"
   },
   "source": [
    "<h2> 3.6 Featurizing text data with tfidf weighted word-vectors </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "-3IbomL8dMTi",
    "outputId": "3fa8eb7c-ddf2-4f98-edee-0c49db6502e8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import sys\n",
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# exctract word2vec vectors\n",
    "# https://github.com/explosion/spaCy/issues/1721\n",
    "# http://landinghub.visualstudio.com/visual-cpp-build-tools\n",
    "import spacy\n",
    "\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "tqdm_notebook.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "j5XNgVyLdMT7"
   },
   "outputs": [],
   "source": [
    "# avoid decoding problems\n",
    "df = pd.read_csv(\"train.csv.zip\")\n",
    " \n",
    "# encode questions to unicode\n",
    "# https://stackoverflow.com/a/6812069\n",
    "# ----------------- python 2 ---------------------\n",
    "# df['question1'] = df['question1'].apply(lambda x: unicode(str(x),\"utf-8\"))\n",
    "# df['question2'] = df['question2'].apply(lambda x: unicode(str(x),\"utf-8\"))\n",
    "# ----------------- python 3 ---------------------\n",
    "df['question1'] = df['question1'].apply(lambda x: str(x))\n",
    "df['question2'] = df['question2'].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "HbiMFpgRdMUJ",
    "outputId": "21c00698-7f2a-4ce4-e665-f7a2feaab6fa"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "RU3HqJXwdMUj"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# merge texts\n",
    "questions = list(df['question1']) + list(df['question2'])\n",
    "\n",
    "tfidf = TfidfVectorizer(lowercase=False, )\n",
    "tfidf.fit_transform(questions)\n",
    "\n",
    "# dict key:word and value:tf-idf score\n",
    "word2tfidf = dict(zip(tfidf.get_feature_names(), tfidf.idf_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "2JKI2yT4dMUv"
   },
   "source": [
    "- After we find TF-IDF scores, we convert each question to a weighted average of word2vec vectors by these scores.\n",
    "- here we use a pre-trained GLOVE model which comes free with \"Spacy\".  https://spacy.io/usage/vectors-similarity\n",
    "- It is trained on Wikipedia and therefore, it is stronger in terms of word semantics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "PFS6m8z5dMUz",
    "outputId": "3c4fb6fd-7f86-4955-8b8f-762b5969ecce"
   },
   "outputs": [],
   "source": [
    "def weighted_tfidf(que):\n",
    "    #vecs = []\n",
    "    #for que in tqdm(list(feature)):\n",
    "    doc = nlp(que) \n",
    "    # 384 is the number of dimensions of vectors \n",
    "    mean_vec = np.zeros([len(doc), len(doc[0].vector)])\n",
    "    for word in doc:\n",
    "        # word2vec\n",
    "        vec = word.vector\n",
    "        # fetch df score\n",
    "        try:\n",
    "            idf = word2tfidf[str(word)]\n",
    "        except:\n",
    "            idf = 0\n",
    "        # compute final vec\n",
    "        mean_vec += vec * idf\n",
    "    mean_vec = mean_vec.mean(axis=0)\n",
    "        #vecs.append(mean_vec)\n",
    "    return mean_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['q1_feats_m'] = df['question1'].progress_apply(weighted_tfidf)\n",
    "df['q2_feats_m'] = df['question2'].progress_apply(weighted_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "a38GBlGWdMVQ"
   },
   "outputs": [],
   "source": [
    "#prepro_features_train.csv (Simple Preprocessing Feartures)\n",
    "#nlp_features_train.csv (NLP Features)\n",
    "if os.path.isfile('nlp_features_train.csv'):\n",
    "    dfnlp = pd.read_csv(\"nlp_features_train.csv\",encoding='latin-1')\n",
    "else:\n",
    "    print(\"download nlp_features_train.csv from drive or run previous notebooks\")\n",
    "\n",
    "if os.path.isfile('train_before_preprocessing.csv'):\n",
    "    dfppro = pd.read_csv(\"train_before_preprocessing.csv\",encoding='latin-1')\n",
    "else:\n",
    "    print(\"download train_before_preprocessing.csv from drive or run previous notebook\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "apdRa1kndMVb"
   },
   "outputs": [],
   "source": [
    "df1 = dfnlp.drop(['qid1','qid2','question1','question2'],axis=1)\n",
    "df2 = dfppro.drop(['qid1','qid2','question1','question2','is_duplicate'],axis=1)\n",
    "df3 = df.drop(['qid1','qid2','question1','question2','is_duplicate'],axis=1)\n",
    "df3_q1 = pd.DataFrame(df3.q1_feats_m.values.tolist(), index= df3.index)\n",
    "df3_q2 = pd.DataFrame(df3.q2_feats_m.values.tolist(), index= df3.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "xzWAqGegdMVp",
    "outputId": "2f88eeda-244f-4bbb-a51c-a8680fe8fb92"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>cwc_min</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>csc_min</th>\n",
       "      <th>csc_max</th>\n",
       "      <th>ctc_min</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>last_word_eq</th>\n",
       "      <th>first_word_eq</th>\n",
       "      <th>abs_len_diff</th>\n",
       "      <th>mean_len</th>\n",
       "      <th>token_set_ratio</th>\n",
       "      <th>token_sort_ratio</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "      <th>fuzz_partial_ratio</th>\n",
       "      <th>longest_substr_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.833319</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.916659</td>\n",
       "      <td>0.785709</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>100</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>100</td>\n",
       "      <td>0.982143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.249997</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.499988</td>\n",
       "      <td>0.499994</td>\n",
       "      <td>0.307690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.5</td>\n",
       "      <td>81</td>\n",
       "      <td>64</td>\n",
       "      <td>66</td>\n",
       "      <td>70</td>\n",
       "      <td>0.553191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.599988</td>\n",
       "      <td>0.499992</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.249997</td>\n",
       "      <td>0.499995</td>\n",
       "      <td>0.357140</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>73</td>\n",
       "      <td>64</td>\n",
       "      <td>41</td>\n",
       "      <td>38</td>\n",
       "      <td>0.188679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>30</td>\n",
       "      <td>32</td>\n",
       "      <td>24</td>\n",
       "      <td>39</td>\n",
       "      <td>0.088235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.399992</td>\n",
       "      <td>0.199998</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.571420</td>\n",
       "      <td>0.307690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>68</td>\n",
       "      <td>49</td>\n",
       "      <td>36</td>\n",
       "      <td>54</td>\n",
       "      <td>0.157895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  is_duplicate   cwc_min   cwc_max   csc_min   csc_max   ctc_min  \\\n",
       "0   0             0  0.999980  0.833319  0.999983  0.999983  0.916659   \n",
       "1   1             0  0.666644  0.249997  0.666644  0.499988  0.499994   \n",
       "2   2             0  0.599988  0.499992  0.399992  0.249997  0.499995   \n",
       "3   3             0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "4   4             0  0.399992  0.199998  0.999950  0.666644  0.571420   \n",
       "\n",
       "    ctc_max  last_word_eq  first_word_eq  abs_len_diff  mean_len  \\\n",
       "0  0.785709           0.0            1.0           2.0      13.0   \n",
       "1  0.307690           0.0            1.0           5.0      10.5   \n",
       "2  0.357140           0.0            1.0           4.0      12.0   \n",
       "3  0.000000           0.0            0.0           4.0       9.0   \n",
       "4  0.307690           0.0            1.0           6.0      10.0   \n",
       "\n",
       "   token_set_ratio  token_sort_ratio  fuzz_ratio  fuzz_partial_ratio  \\\n",
       "0              100                92          92                 100   \n",
       "1               81                64          66                  70   \n",
       "2               73                64          41                  38   \n",
       "3               30                32          24                  39   \n",
       "4               68                49          36                  54   \n",
       "\n",
       "   longest_substr_ratio  \n",
       "0              0.982143  \n",
       "1              0.553191  \n",
       "2              0.188679  \n",
       "3              0.088235  \n",
       "4              0.157895  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataframe of nlp features\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "N4DQnDtndMV4",
    "outputId": "2e288eed-e8fa-4ec3-a9b9-4e4daba52fc1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>freq_qid1</th>\n",
       "      <th>freq_qid2</th>\n",
       "      <th>q1len</th>\n",
       "      <th>q2len</th>\n",
       "      <th>q1_n_words</th>\n",
       "      <th>q2_n_words</th>\n",
       "      <th>word_Common</th>\n",
       "      <th>word_Total</th>\n",
       "      <th>word_share</th>\n",
       "      <th>freq_q1+q2</th>\n",
       "      <th>freq_q1-q2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>57</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>10.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>51</td>\n",
       "      <td>88</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>59</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>4.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>39</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  freq_qid1  freq_qid2  q1len  q2len  q1_n_words  q2_n_words  \\\n",
       "0   0          1          1     66     57          14          12   \n",
       "1   1          4          1     51     88           8          13   \n",
       "2   2          1          1     73     59          14          10   \n",
       "3   3          1          1     50     65          11           9   \n",
       "4   4          3          1     76     39          13           7   \n",
       "\n",
       "   word_Common  word_Total  word_share  freq_q1+q2  freq_q1-q2  \n",
       "0         10.0        23.0    0.434783           2           0  \n",
       "1          4.0        20.0    0.200000           5           3  \n",
       "2          4.0        24.0    0.166667           2           0  \n",
       "3          0.0        19.0    0.000000           2           0  \n",
       "4          2.0        20.0    0.100000           4           2  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data before preprocessing \n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "_1YIPtTwdMWC",
    "outputId": "510f4c73-0706-4633-d706-e0d348ebfa71"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.807843</td>\n",
       "      <td>41.964926</td>\n",
       "      <td>33.081681</td>\n",
       "      <td>4.244238</td>\n",
       "      <td>43.027659</td>\n",
       "      <td>-10.013383</td>\n",
       "      <td>-10.744927</td>\n",
       "      <td>-11.815859</td>\n",
       "      <td>5.588288</td>\n",
       "      <td>1.115522</td>\n",
       "      <td>...</td>\n",
       "      <td>20.576247</td>\n",
       "      <td>-21.568797</td>\n",
       "      <td>-24.228453</td>\n",
       "      <td>14.157065</td>\n",
       "      <td>-16.261115</td>\n",
       "      <td>25.544021</td>\n",
       "      <td>25.480808</td>\n",
       "      <td>39.165071</td>\n",
       "      <td>3.834185</td>\n",
       "      <td>9.871860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-23.079738</td>\n",
       "      <td>14.342906</td>\n",
       "      <td>-0.805506</td>\n",
       "      <td>-19.245326</td>\n",
       "      <td>8.865776</td>\n",
       "      <td>-9.310454</td>\n",
       "      <td>-16.653165</td>\n",
       "      <td>-13.512745</td>\n",
       "      <td>3.500085</td>\n",
       "      <td>-3.910091</td>\n",
       "      <td>...</td>\n",
       "      <td>53.702352</td>\n",
       "      <td>13.131150</td>\n",
       "      <td>-22.455495</td>\n",
       "      <td>-54.181957</td>\n",
       "      <td>0.183353</td>\n",
       "      <td>-3.724258</td>\n",
       "      <td>-12.677888</td>\n",
       "      <td>19.355100</td>\n",
       "      <td>11.162901</td>\n",
       "      <td>19.004885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.112307</td>\n",
       "      <td>18.152627</td>\n",
       "      <td>17.287431</td>\n",
       "      <td>23.381115</td>\n",
       "      <td>25.388425</td>\n",
       "      <td>-6.092771</td>\n",
       "      <td>-20.567529</td>\n",
       "      <td>-15.121522</td>\n",
       "      <td>-2.940608</td>\n",
       "      <td>16.324171</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.378785</td>\n",
       "      <td>-2.544791</td>\n",
       "      <td>-10.461190</td>\n",
       "      <td>16.518055</td>\n",
       "      <td>-21.963829</td>\n",
       "      <td>22.504434</td>\n",
       "      <td>2.132555</td>\n",
       "      <td>8.428122</td>\n",
       "      <td>27.520017</td>\n",
       "      <td>-22.875334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-22.978012</td>\n",
       "      <td>3.542216</td>\n",
       "      <td>-21.203833</td>\n",
       "      <td>6.316206</td>\n",
       "      <td>11.723298</td>\n",
       "      <td>11.653462</td>\n",
       "      <td>-29.423875</td>\n",
       "      <td>2.754801</td>\n",
       "      <td>-17.613957</td>\n",
       "      <td>-12.570249</td>\n",
       "      <td>...</td>\n",
       "      <td>-25.697054</td>\n",
       "      <td>-17.881601</td>\n",
       "      <td>-30.913518</td>\n",
       "      <td>1.010653</td>\n",
       "      <td>8.655211</td>\n",
       "      <td>22.253350</td>\n",
       "      <td>-7.253639</td>\n",
       "      <td>18.266633</td>\n",
       "      <td>51.872220</td>\n",
       "      <td>6.351798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47.606715</td>\n",
       "      <td>76.045652</td>\n",
       "      <td>-16.103146</td>\n",
       "      <td>25.784890</td>\n",
       "      <td>4.649403</td>\n",
       "      <td>-14.228687</td>\n",
       "      <td>-42.204426</td>\n",
       "      <td>32.545716</td>\n",
       "      <td>4.067297</td>\n",
       "      <td>-16.961617</td>\n",
       "      <td>...</td>\n",
       "      <td>22.576464</td>\n",
       "      <td>-35.968549</td>\n",
       "      <td>-19.760356</td>\n",
       "      <td>-52.964732</td>\n",
       "      <td>-60.509826</td>\n",
       "      <td>20.788706</td>\n",
       "      <td>45.909070</td>\n",
       "      <td>44.480312</td>\n",
       "      <td>-28.241497</td>\n",
       "      <td>18.110361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0          1          2          3          4          5   \\\n",
       "0  18.807843  41.964926  33.081681   4.244238  43.027659 -10.013383   \n",
       "1 -23.079738  14.342906  -0.805506 -19.245326   8.865776  -9.310454   \n",
       "2  -0.112307  18.152627  17.287431  23.381115  25.388425  -6.092771   \n",
       "3 -22.978012   3.542216 -21.203833   6.316206  11.723298  11.653462   \n",
       "4  47.606715  76.045652 -16.103146  25.784890   4.649403 -14.228687   \n",
       "\n",
       "          6          7          8          9   ...         86         87  \\\n",
       "0 -10.744927 -11.815859   5.588288   1.115522  ...  20.576247 -21.568797   \n",
       "1 -16.653165 -13.512745   3.500085  -3.910091  ...  53.702352  13.131150   \n",
       "2 -20.567529 -15.121522  -2.940608  16.324171  ...  -2.378785  -2.544791   \n",
       "3 -29.423875   2.754801 -17.613957 -12.570249  ... -25.697054 -17.881601   \n",
       "4 -42.204426  32.545716   4.067297 -16.961617  ...  22.576464 -35.968549   \n",
       "\n",
       "          88         89         90         91         92         93  \\\n",
       "0 -24.228453  14.157065 -16.261115  25.544021  25.480808  39.165071   \n",
       "1 -22.455495 -54.181957   0.183353  -3.724258 -12.677888  19.355100   \n",
       "2 -10.461190  16.518055 -21.963829  22.504434   2.132555   8.428122   \n",
       "3 -30.913518   1.010653   8.655211  22.253350  -7.253639  18.266633   \n",
       "4 -19.760356 -52.964732 -60.509826  20.788706  45.909070  44.480312   \n",
       "\n",
       "          94         95  \n",
       "0   3.834185   9.871860  \n",
       "1  11.162901  19.004885  \n",
       "2  27.520017 -22.875334  \n",
       "3  51.872220   6.351798  \n",
       "4 -28.241497  18.110361  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Questions 1 tfidf weighted word2vec\n",
    "df3_q1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "wUMdkJTNdMWL",
    "outputId": "69e3e256-cbb8-4fe2-aaf2-9088c3868b29"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.710824</td>\n",
       "      <td>37.375986</td>\n",
       "      <td>45.405516</td>\n",
       "      <td>5.426995</td>\n",
       "      <td>33.751131</td>\n",
       "      <td>-3.253420</td>\n",
       "      <td>-4.959911</td>\n",
       "      <td>-13.442803</td>\n",
       "      <td>3.905695</td>\n",
       "      <td>4.777382</td>\n",
       "      <td>...</td>\n",
       "      <td>23.793560</td>\n",
       "      <td>-20.588538</td>\n",
       "      <td>-25.390728</td>\n",
       "      <td>12.380474</td>\n",
       "      <td>-19.671300</td>\n",
       "      <td>16.618838</td>\n",
       "      <td>30.438979</td>\n",
       "      <td>43.384339</td>\n",
       "      <td>5.521896</td>\n",
       "      <td>2.243536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-13.239171</td>\n",
       "      <td>38.161040</td>\n",
       "      <td>31.628311</td>\n",
       "      <td>-9.844968</td>\n",
       "      <td>17.468515</td>\n",
       "      <td>-19.613922</td>\n",
       "      <td>-16.775893</td>\n",
       "      <td>1.972479</td>\n",
       "      <td>-5.051891</td>\n",
       "      <td>6.606223</td>\n",
       "      <td>...</td>\n",
       "      <td>68.032528</td>\n",
       "      <td>1.352752</td>\n",
       "      <td>-25.395078</td>\n",
       "      <td>-7.580498</td>\n",
       "      <td>-23.430201</td>\n",
       "      <td>3.710806</td>\n",
       "      <td>1.435839</td>\n",
       "      <td>44.218947</td>\n",
       "      <td>11.410592</td>\n",
       "      <td>22.943373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.774256</td>\n",
       "      <td>41.910379</td>\n",
       "      <td>11.486097</td>\n",
       "      <td>-2.761912</td>\n",
       "      <td>31.372257</td>\n",
       "      <td>-0.054157</td>\n",
       "      <td>-33.715000</td>\n",
       "      <td>9.834838</td>\n",
       "      <td>-8.615697</td>\n",
       "      <td>-18.969312</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.696379</td>\n",
       "      <td>-35.324791</td>\n",
       "      <td>-20.233565</td>\n",
       "      <td>40.031800</td>\n",
       "      <td>-22.515539</td>\n",
       "      <td>12.892510</td>\n",
       "      <td>0.084740</td>\n",
       "      <td>21.583779</td>\n",
       "      <td>24.523905</td>\n",
       "      <td>-7.576786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.639871</td>\n",
       "      <td>15.257331</td>\n",
       "      <td>8.393493</td>\n",
       "      <td>34.085459</td>\n",
       "      <td>17.597781</td>\n",
       "      <td>2.442303</td>\n",
       "      <td>-16.274006</td>\n",
       "      <td>0.360628</td>\n",
       "      <td>-10.255298</td>\n",
       "      <td>-14.794721</td>\n",
       "      <td>...</td>\n",
       "      <td>6.891580</td>\n",
       "      <td>-21.247972</td>\n",
       "      <td>0.394724</td>\n",
       "      <td>41.386917</td>\n",
       "      <td>-9.613216</td>\n",
       "      <td>18.265161</td>\n",
       "      <td>-1.723291</td>\n",
       "      <td>1.429064</td>\n",
       "      <td>18.121417</td>\n",
       "      <td>18.179006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.878437</td>\n",
       "      <td>30.031709</td>\n",
       "      <td>29.496887</td>\n",
       "      <td>0.223323</td>\n",
       "      <td>16.194255</td>\n",
       "      <td>7.182570</td>\n",
       "      <td>-18.419677</td>\n",
       "      <td>6.949175</td>\n",
       "      <td>11.067374</td>\n",
       "      <td>7.980174</td>\n",
       "      <td>...</td>\n",
       "      <td>17.671461</td>\n",
       "      <td>-11.538394</td>\n",
       "      <td>-11.433049</td>\n",
       "      <td>14.088319</td>\n",
       "      <td>-32.659020</td>\n",
       "      <td>6.244056</td>\n",
       "      <td>20.535059</td>\n",
       "      <td>17.647714</td>\n",
       "      <td>12.484857</td>\n",
       "      <td>-12.859808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 96 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0          1          2          3          4          5   \\\n",
       "0  18.710824  37.375986  45.405516   5.426995  33.751131  -3.253420   \n",
       "1 -13.239171  38.161040  31.628311  -9.844968  17.468515 -19.613922   \n",
       "2   1.774256  41.910379  11.486097  -2.761912  31.372257  -0.054157   \n",
       "3   5.639871  15.257331   8.393493  34.085459  17.597781   2.442303   \n",
       "4   9.878437  30.031709  29.496887   0.223323  16.194255   7.182570   \n",
       "\n",
       "          6          7          8          9   ...         86         87  \\\n",
       "0  -4.959911 -13.442803   3.905695   4.777382  ...  23.793560 -20.588538   \n",
       "1 -16.775893   1.972479  -5.051891   6.606223  ...  68.032528   1.352752   \n",
       "2 -33.715000   9.834838  -8.615697 -18.969312  ... -10.696379 -35.324791   \n",
       "3 -16.274006   0.360628 -10.255298 -14.794721  ...   6.891580 -21.247972   \n",
       "4 -18.419677   6.949175  11.067374   7.980174  ...  17.671461 -11.538394   \n",
       "\n",
       "          88         89         90         91         92         93  \\\n",
       "0 -25.390728  12.380474 -19.671300  16.618838  30.438979  43.384339   \n",
       "1 -25.395078  -7.580498 -23.430201   3.710806   1.435839  44.218947   \n",
       "2 -20.233565  40.031800 -22.515539  12.892510   0.084740  21.583779   \n",
       "3   0.394724  41.386917  -9.613216  18.265161  -1.723291   1.429064   \n",
       "4 -11.433049  14.088319 -32.659020   6.244056  20.535059  17.647714   \n",
       "\n",
       "          94         95  \n",
       "0   5.521896   2.243536  \n",
       "1  11.410592  22.943373  \n",
       "2  24.523905  -7.576786  \n",
       "3  18.121417  18.179006  \n",
       "4  12.484857 -12.859808  \n",
       "\n",
       "[5 rows x 96 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Questions 2 tfidf weighted word2vec\n",
    "df3_q2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "Ozz83vh4dMWU",
    "outputId": "e5b30f77-2849-4b08-9949-0912ec0db418"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features in nlp dataframe : 17\n",
      "Number of features in preprocessed dataframe : 12\n",
      "Number of features in question1 w2v  dataframe : 96\n",
      "Number of features in question2 w2v  dataframe : 96\n",
      "Number of features in final dataframe  : 221\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of features in nlp dataframe :\", df1.shape[1])\n",
    "print(\"Number of features in preprocessed dataframe :\", df2.shape[1])\n",
    "print(\"Number of features in question1 w2v  dataframe :\", df3_q1.shape[1])\n",
    "print(\"Number of features in question2 w2v  dataframe :\", df3_q2.shape[1])\n",
    "print(\"Number of features in final dataframe  :\", df1.shape[1]+df2.shape[1]+df3_q1.shape[1]+df3_q2.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "id": "HmfZ5Q1zdMWl"
   },
   "outputs": [],
   "source": [
    "# storing the final features to csv file\n",
    "if not os.path.isfile('final_features.csv'):\n",
    "    df3_q1['id']=df1['id']\n",
    "    df3_q2['id']=df1['id']\n",
    "    df1  = df1.merge(df2, on='id',how='left')\n",
    "    df2  = df3_q1.merge(df3_q2, on='id',how='left')\n",
    "    result  = df1.merge(df2, on='id',how='left')\n",
    "    result.to_csv('final_features.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'is_duplicate',\n",
       " 'cwc_min',\n",
       " 'cwc_max',\n",
       " 'csc_min',\n",
       " 'csc_max',\n",
       " 'ctc_min',\n",
       " 'ctc_max',\n",
       " 'last_word_eq',\n",
       " 'first_word_eq',\n",
       " 'abs_len_diff',\n",
       " 'mean_len',\n",
       " 'token_set_ratio',\n",
       " 'token_sort_ratio',\n",
       " 'fuzz_ratio',\n",
       " 'fuzz_partial_ratio',\n",
       " 'longest_substr_ratio',\n",
       " 'freq_qid1',\n",
       " 'freq_qid2',\n",
       " 'q1len',\n",
       " 'q2len',\n",
       " 'q1_n_words',\n",
       " 'q2_n_words',\n",
       " 'word_Common',\n",
       " 'word_Total',\n",
       " 'word_share',\n",
       " 'freq_q1+q2',\n",
       " 'freq_q1-q2',\n",
       " '0_x',\n",
       " '1_x',\n",
       " '2_x',\n",
       " '3_x',\n",
       " '4_x',\n",
       " '5_x',\n",
       " '6_x',\n",
       " '7_x',\n",
       " '8_x',\n",
       " '9_x',\n",
       " '10_x',\n",
       " '11_x',\n",
       " '12_x',\n",
       " '13_x',\n",
       " '14_x',\n",
       " '15_x',\n",
       " '16_x',\n",
       " '17_x',\n",
       " '18_x',\n",
       " '19_x',\n",
       " '20_x',\n",
       " '21_x',\n",
       " '22_x',\n",
       " '23_x',\n",
       " '24_x',\n",
       " '25_x',\n",
       " '26_x',\n",
       " '27_x',\n",
       " '28_x',\n",
       " '29_x',\n",
       " '30_x',\n",
       " '31_x',\n",
       " '32_x',\n",
       " '33_x',\n",
       " '34_x',\n",
       " '35_x',\n",
       " '36_x',\n",
       " '37_x',\n",
       " '38_x',\n",
       " '39_x',\n",
       " '40_x',\n",
       " '41_x',\n",
       " '42_x',\n",
       " '43_x',\n",
       " '44_x',\n",
       " '45_x',\n",
       " '46_x',\n",
       " '47_x',\n",
       " '48_x',\n",
       " '49_x',\n",
       " '50_x',\n",
       " '51_x',\n",
       " '52_x',\n",
       " '53_x',\n",
       " '54_x',\n",
       " '55_x',\n",
       " '56_x',\n",
       " '57_x',\n",
       " '58_x',\n",
       " '59_x',\n",
       " '60_x',\n",
       " '61_x',\n",
       " '62_x',\n",
       " '63_x',\n",
       " '64_x',\n",
       " '65_x',\n",
       " '66_x',\n",
       " '67_x',\n",
       " '68_x',\n",
       " '69_x',\n",
       " '70_x',\n",
       " '71_x',\n",
       " '72_x',\n",
       " '73_x',\n",
       " '74_x',\n",
       " '75_x',\n",
       " '76_x',\n",
       " '77_x',\n",
       " '78_x',\n",
       " '79_x',\n",
       " '80_x',\n",
       " '81_x',\n",
       " '82_x',\n",
       " '83_x',\n",
       " '84_x',\n",
       " '85_x',\n",
       " '86_x',\n",
       " '87_x',\n",
       " '88_x',\n",
       " '89_x',\n",
       " '90_x',\n",
       " '91_x',\n",
       " '92_x',\n",
       " '93_x',\n",
       " '94_x',\n",
       " '95_x',\n",
       " '0_y',\n",
       " '1_y',\n",
       " '2_y',\n",
       " '3_y',\n",
       " '4_y',\n",
       " '5_y',\n",
       " '6_y',\n",
       " '7_y',\n",
       " '8_y',\n",
       " '9_y',\n",
       " '10_y',\n",
       " '11_y',\n",
       " '12_y',\n",
       " '13_y',\n",
       " '14_y',\n",
       " '15_y',\n",
       " '16_y',\n",
       " '17_y',\n",
       " '18_y',\n",
       " '19_y',\n",
       " '20_y',\n",
       " '21_y',\n",
       " '22_y',\n",
       " '23_y',\n",
       " '24_y',\n",
       " '25_y',\n",
       " '26_y',\n",
       " '27_y',\n",
       " '28_y',\n",
       " '29_y',\n",
       " '30_y',\n",
       " '31_y',\n",
       " '32_y',\n",
       " '33_y',\n",
       " '34_y',\n",
       " '35_y',\n",
       " '36_y',\n",
       " '37_y',\n",
       " '38_y',\n",
       " '39_y',\n",
       " '40_y',\n",
       " '41_y',\n",
       " '42_y',\n",
       " '43_y',\n",
       " '44_y',\n",
       " '45_y',\n",
       " '46_y',\n",
       " '47_y',\n",
       " '48_y',\n",
       " '49_y',\n",
       " '50_y',\n",
       " '51_y',\n",
       " '52_y',\n",
       " '53_y',\n",
       " '54_y',\n",
       " '55_y',\n",
       " '56_y',\n",
       " '57_y',\n",
       " '58_y',\n",
       " '59_y',\n",
       " '60_y',\n",
       " '61_y',\n",
       " '62_y',\n",
       " '63_y',\n",
       " '64_y',\n",
       " '65_y',\n",
       " '66_y',\n",
       " '67_y',\n",
       " '68_y',\n",
       " '69_y',\n",
       " '70_y',\n",
       " '71_y',\n",
       " '72_y',\n",
       " '73_y',\n",
       " '74_y',\n",
       " '75_y',\n",
       " '76_y',\n",
       " '77_y',\n",
       " '78_y',\n",
       " '79_y',\n",
       " '80_y',\n",
       " '81_y',\n",
       " '82_y',\n",
       " '83_y',\n",
       " '84_y',\n",
       " '85_y',\n",
       " '86_y',\n",
       " '87_y',\n",
       " '88_y',\n",
       " '89_y',\n",
       " '90_y',\n",
       " '91_y',\n",
       " '92_y',\n",
       " '93_y',\n",
       " '94_y',\n",
       " '95_y']"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(result.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "3.Q_Mean_W2V.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
